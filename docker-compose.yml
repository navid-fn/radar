services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "${ZOOKEEPER_CLIENT_PORT:-2181}:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT:-2181}
      ZOOKEEPER_TICK_TIME: ${ZOOKEEPER_TICK_TIME:-2000}
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - dev-network

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID:-1}
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_DEFAULT_REPLICATION_FACTOR:-1}
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_AUTO_CREATE_TOPICS:-true}
      KAFKA_NUM_PARTITIONS: ${KAFKA_NUM_PARTITIONS:-3}
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - dev-network

  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    hostname: clickhouse
    container_name: clickhouse
    ports:
      - "${CLICKHOUSE_HTTP_PORT:-8123}:8123"
      - "${CLICKHOUSE_TCP_PORT:-9000}:9000"
    environment:
      CLICKHOUSE_DB: ${CLICKHOUSE_DB:-default}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER:-default}
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-password}
    volumes:
      - clickhouse-data:/var/lib/clickhouse
      - clickhouse-logs:/var/log/clickhouse-server
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    networks:
      - dev-network

  # Wallex Trades Producer (real-time trades)
  wallex-trades:
    build:
      context: ./drivers
      dockerfile: Dockerfile.wallex
    image: wallex-producer:latest
    container_name: wallex-trades
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      - KAFKA_BROKER=kafka:29092
      - LOG_LEVEL=info
    command: ["./wallex-producer", "-mode", "trades"]
    networks:
      - dev-network
    healthcheck:
      test: ["CMD", "pgrep", "-f", "wallex-producer"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  nobitex-trade:
    build:
      context: ./drivers
      dockerfile: Dockerfile.nobitex
    image: nobitex-producer:latest
    container_name: nobitex-trade
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      - KAFKA_BROKER=kafka:29092
      - LOG_LEVEL=info
    command: ["./nobitex-producer"]
    networks:
      - dev-network
    healthcheck:
      test: ["CMD", "pgrep", "-f", "nobitex-producer"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  bitpin-trade:
    build:
      context: ./drivers
      dockerfile: Dockerfile.bitpin
    image: bitpin-producer:latest
    container_name: bitpin-trade
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      - KAFKA_BROKER=kafka:29092
      - LOG_LEVEL=info
    command: ["./bitpin-producer"]
    networks:
      - dev-network
    healthcheck:
      test: ["CMD", "pgrep", "-f", "nobitex-producer"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  ramzinex-trade:
    build:
      context: ./drivers
      dockerfile: Dockerfile.ramzinex
    image: ramzinex-producer:latest
    container_name: ramzinex-trade
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      - KAFKA_BROKER=kafka:29092
      - LOG_LEVEL=info
    command: ["./ramzinex-producer"]
    networks:
      - dev-network
    healthcheck:
      test: ["CMD", "pgrep", "-f", "nobitex-producer"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  tabdeal-trade:
    build:
      context: ./drivers
      dockerfile: Dockerfile.tabdeal
    image: tabdeal-producer:latest
    container_name: tabdeal-trade
    restart: unless-stopped
    depends_on:
      - kafka
    environment:
      - KAFKA_BROKER=kafka:29092
      - LOG_LEVEL=info
    command: ["./tabdeal-producer"]
    networks:
      - dev-network
    healthcheck:
      test: ["CMD", "pgrep", "-f", "nobitex-producer"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  trades-consumer:
    build:
      context: .
      dockerfile: Dockerfile.consumer
    image: radar-consumer:latest
    container_name: trades-consumer
    restart: unless-stopped
    depends_on:
      - kafka
      - clickhouse
      - wallex-trades
    environment:
      - KAFKA_BROKER=kafka:29092
      - KAFKA_TOPIC=radar_trades
      - KAFKA_GROUP_ID=clickhouse-trades-consumers-v1
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_USER=${CLICKHOUSE_USER:-default}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_PASSWORD:-default}
      - CLICKHOUSE_DB=trades
      - CLICKHOUSE_TABLE=trades_master
      - LOG_LEVEL=INFO
      - BATCH_SIZE=500
      - BATCH_TIMEOUT_SECONDS=5
    command: ["python", "kafka/consumer.py",  "--num-workers", "2"]
    networks:
      - dev-network
    healthcheck:
      test: ["CMD", "pgrep", "-f", "consumer.py"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

volumes:
  zookeeper-data:
    driver: local
  zookeeper-logs:
    driver: local
  kafka-data:
    driver: local
  clickhouse-data:
    driver: local
  clickhouse-logs:
    driver: local

networks:
  dev-network:
    driver: bridge
